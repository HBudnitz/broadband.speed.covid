---
title: "Time series plots"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
---

```{r settings, include = FALSE}
library(tsbox)
library(ggplot2)
library(tidyverse)
library(geojsonio)
library(tsfeatures)
library(rprojroot)
library(openair)
library(reshape2)
library(lubridate)
library(rgdal)
library(maptools)
library(sp)
library(rgeos)
library(classInt)
library(RColorBrewer)
library(knitr)
library(rprojroot)
library(viridis)
library(hrbrthemes)

# This is the project path
path <- find_rstudio_root_file()
```

```{r include = FALSE}

# load and clean the data.
# copied from bbData2020.Rmd

#upload data file
path.data <- paste(path, "./data/raw/speedtest.csv", sep = "")

#bb2020 <- read.csv("./data/raw/speedtest.csv")
bb2020 <- read.csv(path.data)

#name columns
names(bb2020)[1:6] <- c("datetext","speeddown","speedup","provider","lat", "lon") 

str(bb2020)
summary(bb2020) #2030205 obs
#conversions needed to numeric? df$col <- as.numeric(df$col) 
#remove empty rows or coerced to NA? df[complete.cases(df),] or df <- df[!is.na(df$col),]

#remove outliers based on Riddlesden and Singleton 2014 for slower end
#check fastest upload and download speeds commercially available from Virgin Media (Gigaclear offers even faster!)
bb2020 <- bb2020[bb2020$speeddown>512,] 
bb2020 <- bb2020[bb2020$speeddown<362000,]
bb2020 <- bb2020[bb2020$speedup<21000,] #1839333

#remove below seconds, create columns for date and hour
bb2020$datetext <- strtrim(x = bb2020$datetext, width = 19) 
bb2020$datetext2 <- bb2020$datetext
bb2020$datetext2 <- strtrim(x = bb2020$datetext2, width = 13)
bb2020$datetext2 <- colsplit(bb2020$datetext2, pattern = " ", c("date", "hour"))
bb2020$hour <- bb2020$datetext2$hour
bb2020$date <- bb2020$datetext2$date
#delete datetext2 column(s)
bb2020 <- bb2020[ ,c(1:6,8:9)]
#convert to date form datetext and date columns
bb2020$datetext <- as.POSIXct(strptime(bb2020$datetext, format = "%Y-%m-%d %H:%M:%S", "GMT")) 
bb2020$date <- as.POSIXct(strptime(bb2020$date, format = "%Y-%m-%d", "GMT"))
#create dataframe with number of tests, mean and standard deviation by month for adding to dataframe later
MonthFreq <- timeAverage(bb2020, avg.time = "month", statistic = "frequency")
MonthMean <- timeAverage(bb2020, avg.time = "month", statistic = "mean")
MonthSD <- timeAverage(bb2020, avg.time = "month", statistic = "sd")
MonthStats <- cbind(MonthFreq[,1:2], MonthMean[,c(3:4)], 
                    MonthSD[,c(3:4)])
names(MonthStats) <- c("month", "monthlyTests", "monthlyMeanSpDown", 
                       "monthlyMeanSpUp", "monthlySDSpDown", 
                       "monthlySDSpUp")
MonthStats$month <- month(MonthStats$month, label = TRUE, abbr = TRUE)
#add column for month and day of the week to create stats below
bb2020$month <- month(bb2020$date, label = TRUE, abbr = TRUE)
bb2020$weekday <- wday(bb2020$date, label = TRUE)
#divide MonthStats for future join with separate 2019 and 2020 dataframes
MonthStats19 <- MonthStats[1:6,]
MonthStats20 <- MonthStats[13:17,]
```

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=10, fig.width=10}

# Structured TS

# convert to spatial object
coords_bb <- cbind(bb2020$lon, bb2020$lat)
bb.la <- SpatialPointsDataFrame(coords_bb, data = data.frame(bb2020))
proj4string(bb.la) <- CRS("+init=epsg:4326") #define projection

# get LA 
# (i) directly from the web
#la <- readOGR("http://geoportal1-ons.opendata.arcgis.com/datasets/b6d2e15801de45328b760a4f55d74318_0.geojson?outSR={%22latestWkid%22:3857,%22wkid%22:102100}")#, layer="OGRGeoJSON")
# or, (ii) from the json I saved locally
path.json <- paste(path, "./data/raw/Local_Authority_Districts_(April_2019)_Boundaries_UK_BFE.geojson", sep = "")
la <- readOGR(path.json)#, layer="OGRGeoJSON")
# UK BGC la <- readOGR("https://opendata.arcgis.com/datasets/0e07a8196454415eab18c40a54dfbbef_0.geojson")
# UK BFC la <- readOGR("https://opendata.arcgis.com/datasets/1d78d47c87df4212b79fe2323aae8e08_0.geojson") 

# source: https://data.gov.uk/dataset/7c387c64-d25f-474a-b07e-b933578caea2/local-authority-districts-april-2019-boundaries-uk-bfe

# spatial transformations
la <- spTransform(la, CRS("+init=epsg:4326"))
la@data$LAD19NM <- as.character(la@data$LAD19NM)

# spatial join to LAD
bb.la.sp <- over(bb.la, la[, "LAD19NM"]) #not a spatial object
bb.la$LAD19NM <- bb.la.sp$LAD19NM

# create dataframe object to analyse (remove lat and lon?)
bb2020sp <- bb.la@data

# drop NAs
bb2020sp <- bb2020sp[!is.na(bb2020sp$LAD19NM),]
#13431/1839332 = .0073 NA LAD19NM, coord outside UK

# summarise by date and geography
la.date.count <- count(bb2020sp, LAD19NM, date)
la.dateAvg <- summarise(group_by(la.date.count, LAD19NM), mean(n))
range(la.dateAvg$`mean(n)`)

# map LA mean test frequency per date
la@data <- left_join(la@data, la.dateAvg, by = "LAD19NM")
var <- la@data[ ,'mean(n)']
breaks <- classIntervals(var, n = 5, style = "quantile")
my_colours <- brewer.pal(5, "Blues")
plot(la, col = my_colours[findInterval(var, breaks$brks, all.inside = TRUE)], axes = FALSE,
                 border = rgb(0.8, 0.8, 0.8, 0))
# drop LA
rm(la)
```

## Sub-daily timeseries

```{r include=TRUE, echo=FALSE, results= 'markup', message=FALSE, warning = FALSE, fig.height=500, fig.width=12}

# create sub daily blocks
bb2020sp$block[bb2020sp$hour>=0 & bb2020sp$hour<8] <- 1
bb2020sp$block[bb2020sp$hour>=8 & bb2020sp$hour<16] <- 2
bb2020sp$block[bb2020sp$hour>=16 & bb2020sp$hour<24] <- 3

#bb2020sp$date.block <- paste(bb2020sp$date, bb2020sp$date.block, sep = "_")
# I use block as hour for the ts_wide()
bb2020sp$date.block = ymd_h(paste(bb2020sp$date, bb2020sp$block))
head(bb2020sp)

ts <- bb2020sp %>%
  group_by(date.block,LAD19NM) %>%
  summarise(mean.down = mean(speeddown))#, mean.down = mean(speeddown), n.tests = n())
sapply(ts, function(x) sum(is.na(x)))

#hist(ts$n.tests)
#summary(ts$n.tests)
# I am keeping all the obs. despite the n. of tests for now

# spagetti plot
ggplot(ts[ts$LAD19NM=="City of London",], 
       aes(x=as.POSIXct(date.block), y=mean.down, group = LAD19NM, colour = LAD19NM)) +
  geom_line() + guides(colour=FALSE) + ggtitle("City of London") + #xlab("") +
  ylab("download speed") +
  #geom_text_repel(aes(label=outlier.io), cex = 4) + #this line is from the previous version
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

for (i in ts[,2]){
  spaghetti <- ggplot(ts[ts$LAD19NM==i,], 
       aes(x=as.POSIXct(date.block), y=mean.down, group = LAD19NM, colour = LAD19NM)) +
    geom_line() + guides(colour=FALSE) + ggtitle("City of London") + #xlab("") +
    ylab("download speed") +
    #geom_text_repel(aes(label=outlier.io), cex = 4) + #this line is from the previous version
    scale_y_continuous(labels = scales::comma) +
    scale_x_datetime(date_breaks = "1 month") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
    plot.title = element_text(hjust = 0.5))
  print(spaghetti)
}


# https://www.data-to-viz.com/caveat/spaghetti.html
tmp <- ts %>%
  mutate(LAD19NM2=LAD19NM)

tmp %>%
  ggplot( aes(x=as.POSIXct(date.block), y=mean.down)) +
    geom_line( data=tmp %>% dplyr::select(-LAD19NM), aes(group=LAD19NM2), color="grey", size=0.5, alpha=0.5) +
    geom_line( aes(color=LAD19NM), color="#69b3a2", size=1.2 )+
    scale_color_viridis(discrete = TRUE) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=14),
      panel.grid = element_blank()
    ) +
    ggtitle("A spaghetti chart of baby names popularity") +
    facet_wrap(~LAD19NM)


ggplot(subset(ts,date.block>"2019-12-31"), aes(x=as.POSIXct(date.block), y=mean.down, group = LAD19NM, colour = "green")) +
  geom_line() + guides(colour=FALSE) + ggtitle("Download speeds") + #xlab("") +
  stat_summary(fun.y=mean, geom="line", colour="grey", aes(group=1)) + 
  ylab("download speed") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_datetime(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  #geom_vline(xintercept = as.numeric(as.Date("2020-03-01"))) +#, linetype="dashed", color = "blue", size=1.5) +
  facet_wrap(~LAD19NM, ncol = 2)

```
