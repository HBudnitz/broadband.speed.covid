---
title: "descriptive_Clusters"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output")
  })
---

```{r settings, include = FALSE}
library(tsbox)
library(ggplot2)
library(tidyverse)
library(geojsonio)
library(tsfeatures)
library(rprojroot)
library(openair)
library(reshape2)
library(lubridate)
library(rgdal)
library(maptools)
library(sp)
library(rgeos)
library(classInt)
library(RColorBrewer)
library(knitr)
library(rprojroot)
library(viridis)
library(hrbrthemes)

# This is the project path
path <- find_rstudio_root_file()
```


```{r include = FALSE}

# load the data created by Data_Spatial.Rmd and ts_clusters.Rmd

LAD.cluster <- paste(path, "/data/temp/clusters_nodiff.csv", sep = "")

clusters <- read_csv(LAD.cluster)

path.data <- paste(path, "/data/temp/TSbb19_20sp.csv", sep = "")

TSbb19_20sp <- read_csv(path.data)

#split out 2020 before join to clusters to create descriptives
TS2020 <- selectByDate(TSbb19_20sp, year = 2020) 
TS2019 <- selectByDate(TSbb19_20sp, year = 2019)

#join clusters to TS2020
names(clusters) [1] <- "LAD19NM"
TS2020 <- left_join(TS2020, clusters)
TS2019 <- left_join(TS2019, clusters)
#remove NAs? - otherwise cannot create unified dataframes for below stats

#summarise by LADs per cluster and Total tests / Mean speed per cluster
#Test Frequency cluster
LAD.cluster.tests <- clusters %>%
  group_by(cluster.tests) %>%
  summarise(n.LADs = n())
LAD.cluster.testsTotal <- TS2020 %>%
  group_by(cluster.tests) %>%
  summarise(n.cluster = n()) 
LAD.cluster.tests19 <- TS2019 %>%
  group_by(cluster.tests) %>%
  summarise(n.cluster19 = n()) 
LAD.cluster.tests <- cbind(LAD.cluster.tests, LAD.cluster.testsTotal[,2], LAD.cluster.tests19[,2])
LAD.cluster.tests$n.20_19.diff <- LAD.cluster.tests$n.cluster - LAD.cluster.tests$n.cluster19
LAD.cluster.tests$perCent.change <- LAD.cluster.tests$n.20_19.diff/
  LAD.cluster.tests$n.cluster19
LAD.cluster.tests$perCent.change <- paste(round(100*LAD.cluster.tests$perCent.change, 2), "%", sep="")
#Upload Speed Clusters
LAD.cluster.up <- clusters %>%
  group_by(cluster.up) %>%
  summarise(up.LADs = n())
LAD.cluster.upMean <- summarise(group_by(TS2020, cluster.up),
  mean(speedup))
LAD.cluster.upSD <- summarise(group_by(TS2020, cluster.up),
  sd(speedup))
LAD.cluster.upAM <- summarise(group_by(TS2020[which(TS2020$hour == 9 | TS2020$hour == 10),], cluster.up), mean(speedup))
LAD.cluster.upPM <- summarise(group_by(TS2020[which(TS2020$hour == 19 | TS2020$hour == 20),], cluster.up), mean(speedup))
LAD.cluster.up <- cbind(LAD.cluster.up, LAD.cluster.upMean[,2], LAD.cluster.upSD[,2], LAD.cluster.upAM[,2], LAD.cluster.upPM[,2])
names(LAD.cluster.up) [3:6] <- c("upMean", "upSD", "upAMmean",
                                 "upPMmean")
#Download speed clusters  
LAD.cluster.down <- clusters %>%
  group_by(cluster.down) %>%
  summarise(down.LADs = n())
LAD.cluster.downMean <- summarise(group_by(TS2020, cluster.down),
  mean(speeddown))
LAD.cluster.downSD <- summarise(group_by(TS2020, cluster.down),
  sd(speeddown))
LAD.cluster.downAM <- summarise(group_by(TS2020[which(TS2020$hour == 9 | TS2020$hour == 10),], cluster.down), mean(speeddown))
LAD.cluster.downPM <- summarise(group_by(TS2020[which(TS2020$hour == 19 | TS2020$hour == 20),], cluster.down), mean(speeddown))
LAD.cluster.down <- cbind(LAD.cluster.down, LAD.cluster.downMean[,2], LAD.cluster.downSD[,2], LAD.cluster.downAM[,2], LAD.cluster.downPM[,2])
names(LAD.cluster.down)[3:6] <- c("downMean", "downSD", "downAMmean",
                                  "downPMmean")
# commented to run the script
# LAD.cluster.diffUp <- clusters %>%
#   group_by(cluster.up.diff) %>%
#   summarise(diffUp.LADs = n())
# LAD.cluster.diffDown <- clusters %>%
#   group_by(cluster.down.diff) %>%
#   summarise(diffDown.LADs = n())

#write csvs to outputs
out.clustersLAD <- paste(path, "./data/temp/LAD.cluster.tests.csv", sep = "")
write_csv(LAD.cluster.tests, out.clustersLAD)
out.clustersLADup <- paste(path, "./data/temp/LAD.cluster.up.csv", sep = "")
write_csv(LAD.cluster.up, out.clustersLADup)
out.clustersLADdown <- paste(path, "./data/temp/LAD.cluster.down.csv", sep = "")
write_csv(LAD.cluster.down, out.clustersLADdown)

```

As people came to rely more on their broadband services, it is unsurprising that the rate of testing increased in 2020 compared to 2019. This increase was greatest in cluster 2, where 56% more tests were run compared to the same period in 2019. Cluster 2 also has the most local authorities, 148, so the sum of tests run in all these authorities is much higher than in all the other clusters, both in 2019 and 2020. Cluster 1 has the second most local authorities, with 93, but the frequency of testing in these authorities is much lower in 2019 and 2020 and there was the lowest rate of increase between the two time periods at just 33%. In comparison, cluster 5 has the fewest local authorities, at 28, but the second highest total number of tests and the second largest increase in testing between 2019 and 2020, at 52%. A possible explanation is that cluster 5 contains some of the most populous local authorities in the country, including the cities of Birmingham, Manchester, Leeds, Sheffield, Glasgow and Edinburgh. However, this cluster also includes large rural counties, such as Cornwall and Northumberland.
Yet the temporal profile in 2020 is very different to 2019, as can be seen in graphs [.] and [.]. The number of broadband speed tests run in local authorities in cluster 2 peaked each Monday to Thursday in the hour 19.00-19.59 in March through May 2019. On Fridays, the peak was slightly earlier. A similar, although less stark pattern could be seen in the other clusters, along with much smaller peaks around the beginning of the working day, at either 9.00-9.59 or 10.00-10.59.

```{r }
#summarise test frequency clusters by hour of each weekday and plot
cluster.tests <- TS2020 %>%
  group_by(cluster.tests, weekday, hour) %>%
  summarise(n.tests = n())
names(cluster.tests)[1] <- "clusterID"
cluster.tests$clusterID <- as.factor(cluster.tests$clusterID)
#add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2020, month = 3, day = 2),
  make_datetime(year = 2020, month = 3, day = 3),
  make_datetime(year = 2020, month = 3, day = 4),
  make_datetime(year = 2020, month = 3, day = 5),
  make_datetime(year = 2020, month = 3, day = 6)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.tests <- merge(cluster.tests, help.dates, by = "weekday")
cluster.tests$hour <- paste(cluster.tests$hour, ":00", sep="")
cluster.tests$help.date.time <- with(cluster.tests, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))
#plot cluster statistic for number tests
TestCluster <- ggplot(cluster.tests, aes(help.date.time, n.tests, 
                                         colour = clusterID))
TestCluster + geom_line() + labs(x = "Weekdays March-May") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + geom_point()
#summarise test frequency clusters by hour of each weekday 2019 and plot
cluster.tests19 <- TS2019 %>%
  group_by(cluster.tests, weekday, hour) %>%
  summarise(n.tests = n())
names(cluster.tests19)[1] <- "clusterID"
cluster.tests19$clusterID <- as.factor(cluster.tests19$clusterID)
#add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2019, month = 3, day = 4),
  make_datetime(year = 2019, month = 3, day = 5),
  make_datetime(year = 2019, month = 3, day = 6),
  make_datetime(year = 2019, month = 3, day = 7),
  make_datetime(year = 2019, month = 3, day = 8)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.tests19 <- merge(cluster.tests19, help.dates, by = "weekday")
cluster.tests19$hour <- paste(cluster.tests19$hour, ":00", sep="")
cluster.tests19$help.date.time <- with(cluster.tests19, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))
#plot cluster statistic for number tests
TestCluster19 <- ggplot(cluster.tests19, aes(help.date.time, n.tests, 
                                         colour = clusterID))
TestCluster19 + geom_line() + labs(x = "Weekdays March-May 2019") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + geom_point()
#summarise upload speed clusters by hour of each weekday and plot
cluster.up <- TS2020 %>%
  group_by(cluster.up, weekday, hour) %>%
  summarise(mean.up = mean(speedup))
names(cluster.up)[1] <- "clusterID"
names(LAD.cluster.up)[1] <- "clusterID"
cluster.up <- left_join(cluster.up, LAD.cluster.up)
cluster.up <- cluster.up[which(cluster.up$up.LADs > 5),]
cluster.up$clusterID <- as.factor(cluster.up$clusterID)
#add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2020, month = 3, day = 2),
  make_datetime(year = 2020, month = 3, day = 3),
  make_datetime(year = 2020, month = 3, day = 4),
  make_datetime(year = 2020, month = 3, day = 5),
  make_datetime(year = 2020, month = 3, day = 6)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.up <- merge(cluster.up, help.dates, by = "weekday")
cluster.up$hour <- paste(cluster.up$hour, ":00", sep="")
cluster.up$help.date.time <- with(cluster.up, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))
#plot cluster statistic for mean upload speed
UpCluster <- ggplot(cluster.up, aes(help.date.time, mean.up, 
                                         colour = clusterID))
UpCluster + geom_line() + labs(x = "Weekdays March-May") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + geom_point()

#summarise download speed clusters by hour of each weekday and plot
cluster.down <- TS2020 %>%
  group_by(cluster.down, weekday, hour) %>%
  summarise(mean.down = mean(speeddown))
names(cluster.down)[1] <- "clusterID"
names(LAD.cluster.down)[1] <- "clusterID"
cluster.down <- left_join(cluster.down, LAD.cluster.down)
cluster.down <- cluster.down[which(cluster.down$down.LADs > 5),]
cluster.down$clusterID <- as.factor(cluster.down$clusterID)
#add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2020, month = 3, day = 2),
  make_datetime(year = 2020, month = 3, day = 3),
  make_datetime(year = 2020, month = 3, day = 4),
  make_datetime(year = 2020, month = 3, day = 5),
  make_datetime(year = 2020, month = 3, day = 6)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.down <- merge(cluster.down, help.dates, by = "weekday")
cluster.down$hour <- paste(cluster.down$hour, ":00", sep="")
cluster.down$help.date.time <- with(cluster.down, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))
#plot cluster statistic for mean download speeds
TestCluster <- ggplot(cluster.down, aes(help.date.time, mean.down, 
                                         colour = clusterID))
TestCluster + geom_line() + labs(x = "Weekdays March-May") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + geom_point()

```

