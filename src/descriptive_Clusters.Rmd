---
title: "descriptive_Clusters"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output")
  })
---

```{r settings, include = FALSE}
library(tsbox)
library(ggplot2)
library(tidyverse)
library(geojsonio)
library(tsfeatures)
library(rprojroot)
library(openair)
library(reshape2)
library(lubridate)
library(rgdal)
library(maptools)
library(sp)
library(rgeos)
library(classInt)
library(RColorBrewer)
library(knitr)
library(rprojroot)
library(viridis)
library(hrbrthemes)

# This is the project path
path <- find_rstudio_root_file()
```

## Time variation plots (Figures 1 and 2)

```{r include = FALSE}

# load the data created by Data_Spatial.Rmd and ts_clusters.Rmd

LAD.cluster <- paste(path, "/data/temp/clusters_nodiff_9.csv", sep = "")

clusters <- read_csv(LAD.cluster)

path.data <- paste(path, "/data/temp/TSbb19_20sp.csv", sep = "")

TSbb19_20sp <- read_csv(path.data)

#split out 2020 before join to clusters to create descriptives
TS2020 <- selectByDate(TSbb19_20sp, year = 2020) 
TS2019 <- selectByDate(TSbb19_20sp, year = 2019)

#create time variation plots for speedtests for each year
Tests19 <- count(TS2019, date)
TS2019 <- left_join(TS2019, Tests19)
names(TS2019)[13] <- "test frequency 2019"
time.var.plot2019 <- timeVariation(TS2019, pollutant = "test frequency 2019", statistic = "mean",
                                   par.settings=list(fontsize=list(text=8)))
Tests20 <- count(TS2020, date)
TS2020 <- left_join(TS2020, Tests20)
names(TS2020)[13] <- "test frequency 2020"
time.var.plot2020 <- timeVariation(TS2020, pollutant = "test frequency 2020", statistic = "mean",
                                   par.settings=list(fontsize=list(text=8)))

#export time variation plots for paper
out.plot <- paste(path, "/paper/v2_taylor_francis/figures/time.var.plot2019.png", sep = "")
png(out.plot, res = 100, width = 615, height = 615) # 72dpi default res. 480x480. 
                                                    # ((100-72)/100)*480+480 = 615 
time.var.plot2019
dev.off() # if dev.off() doesn't work try dev.set(dev.next()) 2-3 times

out.plot <- paste(path, "/paper/v2_taylor_francis/figures/time.var.plot2020.png", sep = "")
png(out.plot, res = 100, width = 615, height = 615)
time.var.plot2020
dev.off()
```



```{r}
#join clusters to TS2020
names(clusters) [1] <- "LAD19NM"
TS2020 <- left_join(TS2020, clusters)
TS2019 <- left_join(TS2019, clusters)
#remove NAs? - otherwise cannot create unified dataframes for below stats

#add LAD population data
pop <- read_csv("https://www.nomisweb.co.uk/api/v01/dataset/NM_31_1.data.csv?geography=1820327937...1820328318,1816133633...1816133848&date=latestMINUS1-latest&sex=7&age=0,22&measures=20100")

pop <- pop %>%
  dplyr::select(GEOGRAPHY_CODE, GEOGRAPHY_NAME, AGE_NAME, OBS_VALUE) %>%
  distinct(GEOGRAPHY_NAME, AGE_NAME, .keep_all = T) %>% 
  spread(AGE_NAME, OBS_VALUE) %>% 
  rename(pop16_64 = `Aged 16 - 64`) %>%
  rename(pop = `All ages`) %>%
  rename(LAD19NM = GEOGRAPHY_NAME)
  
#join to clusters
pop$LAD19NM <- if_else(pop$LAD19NM == "Rhondda Cynon Taff", "Rhondda Cynon Taf", pop$LAD19NM)
clusters <- left_join(clusters, pop)

#summarise by LADs per upload cluster
#Upload Speed Clusters
LAD.cluster.up <- clusters %>%
  group_by(cluster.up) %>%
  summarise(up.LADs = n())
LAD.cluster.upPop <- clusters %>%
  group_by(cluster.up) %>%
  summarise(pop.LADs = sum(pop))
LAD.cluster.upMean <- summarise(group_by(TS2020, cluster.up),
  mean(speedup))
LAD.cluster.upSD <- summarise(group_by(TS2020, cluster.up),
  sd(speedup))
LAD.cluster.upAM <- summarise(group_by(TS2020[which(TS2020$hour == 9 | TS2020$hour == 10),], cluster.up), mean(speedup))
LAD.cluster.upPM <- summarise(group_by(TS2020[which(TS2020$hour == 19 | TS2020$hour == 20),], cluster.up), mean(speedup))
LAD.cluster.up <- cbind(LAD.cluster.up, LAD.cluster.upPop[,2], LAD.cluster.upMean[,2], LAD.cluster.upSD[,2], LAD.cluster.upAM[,2], LAD.cluster.upPM[,2])
names(LAD.cluster.up) [4:7] <- c("upMean", "upSD", "upAMmean",
                                 "upPMmean")
LAD.cluster.up$AM_slower <- (LAD.cluster.up$upPMmean - LAD.cluster.up$upAMmean) / LAD.cluster.up$upPMmean
LAD.cluster.up$SDtoMean <- LAD.cluster.up$upSD/LAD.cluster.up$upMean
LAD.cluster.up$AM_slower <- paste(round(100*LAD.cluster.up$AM_slower, 2), "%", sep="")
LAD.cluster.up$SDtoMean <- paste(round(100*LAD.cluster.up$SDtoMean, 2), "%", sep="")
#write csv to outputs
out.clustersLADup <- paste(path, "./data/temp/LAD.cluster.up.csv", sep = "")
write_csv(LAD.cluster.up, out.clustersLADup)

```

## Summarise 2020 upload speed clusters by hour of each weekday and plot

```{r}

# plot largest 6 clusters - all over 500k pop
cluster.up <- TS2020 %>%
  group_by(cluster.up, weekday, hour) %>%
  summarise(mean.up = mean(speedup))
names(cluster.up)[1] <- "clusterID"
names(LAD.cluster.up)[1] <- "clusterID"
cluster.up <- left_join(cluster.up, LAD.cluster.up)
cluster.up <- cluster.up[which(cluster.up$up.LADs > 4),]
cluster.up$clusterID <- as.factor(cluster.up$clusterID)

# add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2020, month = 3, day = 2),
  make_datetime(year = 2020, month = 3, day = 3),
  make_datetime(year = 2020, month = 3, day = 4),
  make_datetime(year = 2020, month = 3, day = 5),
  make_datetime(year = 2020, month = 3, day = 6)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.up <- merge(cluster.up, help.dates, by = "weekday")
cluster.up$hour <- paste(cluster.up$hour, ":00", sep="")
cluster.up$help.date.time <- with(cluster.up, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))

# plot cluster statistic for mean upload speed
UpCluster <- ggplot(cluster.up, aes(help.date.time, mean.up, 
                                      colour = clusterID)) +
  theme_minimal() +
  geom_line() + 
  labs(x = "Weekdays March-May", y = "mean upload speed", col = "Cluster ID") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + 
  geom_point() +
  theme(legend.position = c(0.7, 0.08),
        legend.direction = "horizontal")

#export UpCluster plot for paper
out.plot <- paste(path, "/paper/v2_taylor_francis/figures/UpCluster.png", sep = "")
UpCluster
ggsave(out.plot)

# EXCLUDED from paper
# plot next 6 smaller clusters, but exclude 2 clusters with 1 LAD and under 100k pop
cluster.upS <- TS2020 %>%
  group_by(cluster.up, weekday, hour) %>%
  summarise(mean.up = mean(speedup))
names(cluster.upS)[1] <- "clusterID"
names(LAD.cluster.up)[1] <- "clusterID"
cluster.upS <- left_join(cluster.upS, LAD.cluster.up)
cluster.upS <- cluster.upS[which(cluster.upS$up.LADs < 10 & cluster.upS$up.LADs > 1),]
cluster.upS$clusterID <- as.factor(cluster.upS$clusterID)

# add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2020, month = 3, day = 2),
  make_datetime(year = 2020, month = 3, day = 3),
  make_datetime(year = 2020, month = 3, day = 4),
  make_datetime(year = 2020, month = 3, day = 5),
  make_datetime(year = 2020, month = 3, day = 6)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.upS <- merge(cluster.upS, help.dates, by = "weekday")
cluster.upS$hour <- paste(cluster.upS$hour, ":00", sep="")
cluster.upS$help.date.time <- with(cluster.upS, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))

# plot cluster statistic for mean upload speed
UpClusterS <- ggplot(cluster.upS, aes(help.date.time, mean.up, 
                                      colour = clusterID)) +
  theme_minimal() +
  geom_line() + 
  labs(x = "Weekdays March-May", y = "mean upload speed", col = "Cluster ID") + 
  scale_x_datetime(breaks = as.POSIXct(c("2020-03-02 15:00:00", 
                    "2020-03-03 15:00:00", "2020-03-04 15:00:00",
                    "2020-03-05 15:00:00", "2020-03-06 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + 
  geom_point() +
  theme(legend.position = c(0.8, 0.08),
        legend.direction = "horizontal")
        
# The figure with the small clusters is not included in the paper
#export UpClusterS plot for paper
#out.plot <- paste(path, "/paper/v2_taylor_francis/figures/UpClusterS.png", sep = "")
#png(out.plot)
#UpClusterS
#dev.off() 
```

## Summarise 2019 upload speed clusters by hour of each weekday and plot

This is a test to compare 2020 vs. 2019 line graphs.

```{r}

# plot largest 6 clusters - all over 500k pop
cluster.up <- TS2019 %>%
  group_by(cluster.up, weekday, hour) %>%
  summarise(mean.up = mean(speedup))
names(cluster.up)[1] <- "clusterID"
names(LAD.cluster.up)[1] <- "clusterID"
cluster.up <- left_join(cluster.up, LAD.cluster.up)
cluster.up <- cluster.up[which(cluster.up$up.LADs > 4),]
cluster.up$clusterID <- as.factor(cluster.up$clusterID)

# add fake dates for plotting
help.dates <- tibble(help.date.time = c(
  make_datetime(year = 2019, month = 3, day = 4),
  make_datetime(year = 2019, month = 3, day = 5),
  make_datetime(year = 2019, month = 3, day = 6),
  make_datetime(year = 2019, month = 3, day = 7),
  make_datetime(year = 2019, month = 3, day = 8)),
                     weekday = c("Mon", "Tue", "Wed", "Thu", "Fri"))
cluster.up <- merge(cluster.up, help.dates, by = "weekday")
cluster.up$hour <- paste(cluster.up$hour, ":00", sep="")
cluster.up$help.date.time <- with(cluster.up, as.POSIXct(paste(help.date.time, hour), format="%Y-%m-%d %H:%M"))

# plot cluster statistic for mean upload speed
UpCluster2019 <- ggplot(cluster.up, aes(help.date.time, mean.up, 
                                      colour = clusterID)) +
  theme_minimal() +
  geom_line() + 
  labs(x = "Weekdays March-May", y = "mean upload speed", col = "Cluster ID") + 
  scale_x_datetime(breaks = as.POSIXct(c("2019-03-04 15:00:00", 
                    "2019-03-05 15:00:00", "2019-03-06 15:00:00",
                    "2019-03-07 15:00:00", "2019-03-08 15:00:00"), 
                    labels = "%a"), labels = 
                     c("Mon", "Tues", "Weds", "Thurs", "Fri")) + 
  geom_point() +
  theme(legend.position = c(0.7, 0.08),
        legend.direction = "horizontal")

#export UpCluster plot for paper
out.plot <- paste(path, "/paper/v2_taylor_francis/figures/UpCluster2019.png", sep = "")
UpCluster2019
ggsave(out.plot)
```

